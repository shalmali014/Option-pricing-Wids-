{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6b49dba4-f951-4250-8ea7-afc2516ae240",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, LeakyReLU, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "adead9bf-4aee-44ac-95b8-6a925c6cef61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Expiry</th>\n",
       "      <th>t</th>\n",
       "      <th>strike_price</th>\n",
       "      <th>underlying_value</th>\n",
       "      <th>sigma</th>\n",
       "      <th>r</th>\n",
       "      <th>close</th>\n",
       "      <th>T</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>2020-01-30</td>\n",
       "      <td>29</td>\n",
       "      <td>1980</td>\n",
       "      <td>1793.2</td>\n",
       "      <td>0.008151</td>\n",
       "      <td>0.0494</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0.079452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>2020-01-30</td>\n",
       "      <td>29</td>\n",
       "      <td>1440</td>\n",
       "      <td>1793.2</td>\n",
       "      <td>0.008151</td>\n",
       "      <td>0.0494</td>\n",
       "      <td>398.5</td>\n",
       "      <td>0.079452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>2020-01-30</td>\n",
       "      <td>29</td>\n",
       "      <td>2020</td>\n",
       "      <td>1793.2</td>\n",
       "      <td>0.008151</td>\n",
       "      <td>0.0494</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.079452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>2020-01-30</td>\n",
       "      <td>29</td>\n",
       "      <td>1920</td>\n",
       "      <td>1793.2</td>\n",
       "      <td>0.008151</td>\n",
       "      <td>0.0494</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.079452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>2020-01-30</td>\n",
       "      <td>29</td>\n",
       "      <td>1940</td>\n",
       "      <td>1793.2</td>\n",
       "      <td>0.008151</td>\n",
       "      <td>0.0494</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.079452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date     Expiry   t  strike_price  underlying_value     sigma       r  \\\n",
       "0 2020-01-01 2020-01-30  29          1980            1793.2  0.008151  0.0494   \n",
       "1 2020-01-01 2020-01-30  29          1440            1793.2  0.008151  0.0494   \n",
       "2 2020-01-01 2020-01-30  29          2020            1793.2  0.008151  0.0494   \n",
       "3 2020-01-01 2020-01-30  29          1920            1793.2  0.008151  0.0494   \n",
       "4 2020-01-01 2020-01-30  29          1940            1793.2  0.008151  0.0494   \n",
       "\n",
       "   close         T  \n",
       "0    3.8  0.079452  \n",
       "1  398.5  0.079452  \n",
       "2    1.2  0.079452  \n",
       "3    6.5  0.079452  \n",
       "4    5.0  0.079452  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('ASIANPAINT_Dataset.xlsx')\n",
    "df[\"T\"] = df[\"t\"] / 365.0\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3483856a-c990-409d-b7c4-67a152080406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 35591 entries, 0 to 35590\n",
      "Data columns (total 9 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   Date              35591 non-null  datetime64[ns]\n",
      " 1   Expiry            35591 non-null  datetime64[ns]\n",
      " 2   t                 35591 non-null  int64         \n",
      " 3   strike_price      35591 non-null  int64         \n",
      " 4   underlying_value  35591 non-null  float64       \n",
      " 5   sigma             35591 non-null  float64       \n",
      " 6   r                 35591 non-null  float64       \n",
      " 7   close             35591 non-null  float64       \n",
      " 8   T                 35591 non-null  float64       \n",
      "dtypes: datetime64[ns](2), float64(5), int64(2)\n",
      "memory usage: 2.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "057fbaff-ff82-4e14-bb30-7418e804fb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    \"underlying_value\",\n",
    "    \"strike_price\",\n",
    "    \"T\",\n",
    "    \"r\",\n",
    "    \"sigma\"\n",
    "]\n",
    "X = df[features].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d81405d7-bbfa-4ef6-8ee4-7fc5863bf251",
   "metadata": {},
   "outputs": [],
   "source": [
    "spread = 0.005 \n",
    "bid = df[\"close\"].values * (1 - spread)\n",
    "ask = df[\"close\"].values * (1 + spread)\n",
    "\n",
    "y = np.column_stack((bid, ask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fae99cea-6629-480e-9fc6-4032f80dc5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.02, random_state=42\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "50f53f91-a4c1-4ffa-b848-4d90f0a1d5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val   = scaler.transform(X_val)\n",
    "X_test  = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "02905394-d758-4e08-b9a8-750ca72e96bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mlp2(input_dim):\n",
    "    inputs = Input(shape=(input_dim,))\n",
    "\n",
    "    x = Dense(400, kernel_initializer=\"glorot_uniform\")(inputs)\n",
    "    x = LeakyReLU(alpha=0.01)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Dense(400, kernel_initializer=\"glorot_uniform\")(x)\n",
    "    x = LeakyReLU(alpha=0.01)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Dense(400, kernel_initializer=\"glorot_uniform\")(x)\n",
    "    x = LeakyReLU(alpha=0.01)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    outputs = Dense(2, activation=\"relu\")(x) \n",
    "    return Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8af7c717-c644-4efd-92b9-292d15adc14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "    if epoch < 30:\n",
    "        return 1e-3\n",
    "    elif epoch < 40:\n",
    "        return 1e-4\n",
    "    elif epoch < 50:\n",
    "        return 1e-5\n",
    "    else:\n",
    "        return 1e-6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6d40703d-3f51-4529-84c2-5bb9d0139e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rodes\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\activations\\leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 278ms/step - loss: 70603.3594 - mse: 70603.3594 - val_loss: 60697.0898 - val_mse: 60697.0898 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 226ms/step - loss: 68125.0547 - mse: 68125.0547 - val_loss: 60332.9648 - val_mse: 60332.9648 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - loss: 66177.8828 - mse: 66177.8828 - val_loss: 60043.7656 - val_mse: 60043.7656 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 205ms/step - loss: 64232.9141 - mse: 64232.9141 - val_loss: 59858.7188 - val_mse: 59858.7188 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 201ms/step - loss: 62885.8945 - mse: 62885.8945 - val_loss: 59782.5859 - val_mse: 59782.5859 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 208ms/step - loss: 61493.9531 - mse: 61493.9531 - val_loss: 59886.7852 - val_mse: 59886.7852 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 208ms/step - loss: 58742.2578 - mse: 58742.2578 - val_loss: 59863.8047 - val_mse: 59863.8047 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 210ms/step - loss: 57360.1953 - mse: 57360.1953 - val_loss: 59670.5234 - val_mse: 59670.5234 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 208ms/step - loss: 54651.7461 - mse: 54651.7461 - val_loss: 59373.8711 - val_mse: 59373.8711 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 212ms/step - loss: 52994.7344 - mse: 52994.7344 - val_loss: 59141.2695 - val_mse: 59141.2695 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200ms/step - loss: 51217.4609 - mse: 51217.4609 - val_loss: 58740.0117 - val_mse: 58740.0117 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 212ms/step - loss: 49351.2305 - mse: 49351.2305 - val_loss: 58370.5625 - val_mse: 58370.5625 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 198ms/step - loss: 47821.6836 - mse: 47821.6836 - val_loss: 57777.7852 - val_mse: 57777.7852 - learning_rate: 0.0010\n",
      "Epoch 14/60\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 209ms/step - loss: 45488.1719 - mse: 45488.1719 - val_loss: 57110.0781 - val_mse: 57110.0781 - learning_rate: 0.0010\n",
      "Epoch 15/60\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 216ms/step - loss: 43632.7695 - mse: 43632.7695 - val_loss: 56676.5117 - val_mse: 56676.5117 - learning_rate: 0.0010\n",
      "Epoch 16/60\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 176ms/step - loss: 42224.4258 - mse: 42224.4258 - val_loss: 56032.7070 - val_mse: 56032.7070 - learning_rate: 0.0010\n",
      "Epoch 17/60\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 216ms/step - loss: 39725.1641 - mse: 39725.1641 - val_loss: 55338.0352 - val_mse: 55338.0352 - learning_rate: 0.0010\n",
      "Epoch 18/60\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 234ms/step - loss: 37876.4531 - mse: 37876.4531 - val_loss: 54274.4219 - val_mse: 54274.4219 - learning_rate: 0.0010\n",
      "Epoch 19/60\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 205ms/step - loss: 35795.9062 - mse: 35795.9062 - val_loss: 53214.8633 - val_mse: 53214.8633 - learning_rate: 0.0010\n",
      "Epoch 20/60\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196ms/step - loss: 34355.8242 - mse: 34355.8242 - val_loss: 51930.7852 - val_mse: 51930.7852 - learning_rate: 0.0010\n",
      "Epoch 21/60\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 228ms/step - loss: 32762.0898 - mse: 32762.0898 - val_loss: 50995.7852 - val_mse: 50995.7852 - learning_rate: 0.0010\n",
      "Epoch 22/60\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 209ms/step - loss: 30646.5410 - mse: 30646.5410 - val_loss: 50269.3359 - val_mse: 50269.3359 - learning_rate: 0.0010\n",
      "Epoch 23/60\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 209ms/step - loss: 28975.8867 - mse: 28975.8867 - val_loss: 50461.5000 - val_mse: 50461.5000 - learning_rate: 0.0010\n",
      "Epoch 24/60\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 219ms/step - loss: 27584.8203 - mse: 27584.8203 - val_loss: 49068.3594 - val_mse: 49068.3594 - learning_rate: 0.0010\n",
      "Epoch 25/60\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 204ms/step - loss: 25843.9102 - mse: 25843.9102 - val_loss: 48335.5391 - val_mse: 48335.5391 - learning_rate: 0.0010\n",
      "Epoch 26/60\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 213ms/step - loss: 24139.3398 - mse: 24139.3398 - val_loss: 45972.2734 - val_mse: 45972.2734 - learning_rate: 0.0010\n",
      "Epoch 27/60\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 227ms/step - loss: 22813.8281 - mse: 22813.8281 - val_loss: 44966.1641 - val_mse: 44966.1641 - learning_rate: 0.0010\n",
      "Epoch 28/60\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200ms/step - loss: 21023.8516 - mse: 21023.8516 - val_loss: 44971.8750 - val_mse: 44971.8750 - learning_rate: 0.0010\n",
      "Epoch 29/60\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 181ms/step - loss: 19743.7910 - mse: 19743.7910 - val_loss: 42685.5273 - val_mse: 42685.5273 - learning_rate: 0.0010\n",
      "Epoch 30/60\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 199ms/step - loss: 17731.1035 - mse: 17731.1035 - val_loss: 43042.5156 - val_mse: 43042.5156 - learning_rate: 0.0010\n",
      "Epoch 31/60\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 203ms/step - loss: 17142.2441 - mse: 17142.2441 - val_loss: 42199.1680 - val_mse: 42199.1680 - learning_rate: 1.0000e-04\n",
      "Epoch 32/60\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 146ms/step - loss: 16970.3359 - mse: 16970.3359 - val_loss: 42004.5000 - val_mse: 42004.5000 - learning_rate: 1.0000e-04\n",
      "Epoch 33/60\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 150ms/step - loss: 16984.8398 - mse: 16984.8398 - val_loss: 41346.4297 - val_mse: 41346.4297 - learning_rate: 1.0000e-04\n",
      "Epoch 34/60\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 208ms/step - loss: 17004.7070 - mse: 17004.7070 - val_loss: 40965.1445 - val_mse: 40965.1445 - learning_rate: 1.0000e-04\n",
      "Epoch 35/60\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 211ms/step - loss: 16777.0039 - mse: 16777.0039 - val_loss: 40288.1875 - val_mse: 40288.1875 - learning_rate: 1.0000e-04\n",
      "Epoch 36/60\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 215ms/step - loss: 16262.0732 - mse: 16262.0732 - val_loss: 39710.0430 - val_mse: 39710.0430 - learning_rate: 1.0000e-04\n",
      "Epoch 37/60\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 300ms/step - loss: 16187.5332 - mse: 16187.5332 - val_loss: 39007.5938 - val_mse: 39007.5938 - learning_rate: 1.0000e-04\n",
      "Epoch 38/60\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 145ms/step - loss: 15994.2520 - mse: 15994.2520 - val_loss: 38306.1914 - val_mse: 38306.1914 - learning_rate: 1.0000e-04\n",
      "Epoch 39/60\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 153ms/step - loss: 16164.7256 - mse: 16164.7256 - val_loss: 37759.7930 - val_mse: 37759.7930 - learning_rate: 1.0000e-04\n",
      "Epoch 40/60\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 151ms/step - loss: 15776.2676 - mse: 15776.2676 - val_loss: 37034.5469 - val_mse: 37034.5469 - learning_rate: 1.0000e-04\n",
      "Epoch 41/60\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 152ms/step - loss: 15589.2051 - mse: 15589.2051 - val_loss: 36344.4453 - val_mse: 36344.4453 - learning_rate: 1.0000e-05\n",
      "Epoch 42/60\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 145ms/step - loss: 15880.9365 - mse: 15880.9365 - val_loss: 35675.5039 - val_mse: 35675.5039 - learning_rate: 1.0000e-05\n",
      "Epoch 43/60\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 143ms/step - loss: 15936.7930 - mse: 15936.7930 - val_loss: 35014.4219 - val_mse: 35014.4219 - learning_rate: 1.0000e-05\n",
      "Epoch 44/60\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 146ms/step - loss: 15800.1104 - mse: 15800.1104 - val_loss: 34347.7852 - val_mse: 34347.7852 - learning_rate: 1.0000e-05\n",
      "Epoch 45/60\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 209ms/step - loss: 15880.6309 - mse: 15880.6309 - val_loss: 33629.1445 - val_mse: 33629.1445 - learning_rate: 1.0000e-05\n",
      "Epoch 46/60\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 210ms/step - loss: 15617.2324 - mse: 15617.2324 - val_loss: 32910.1797 - val_mse: 32910.1797 - learning_rate: 1.0000e-05\n",
      "Epoch 47/60\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 210ms/step - loss: 15783.2842 - mse: 15783.2842 - val_loss: 32211.3711 - val_mse: 32211.3711 - learning_rate: 1.0000e-05\n",
      "Epoch 48/60\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 217ms/step - loss: 15697.2207 - mse: 15697.2207 - val_loss: 31480.9316 - val_mse: 31480.9316 - learning_rate: 1.0000e-05\n",
      "Epoch 49/60\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 211ms/step - loss: 15814.2539 - mse: 15814.2539 - val_loss: 30730.2676 - val_mse: 30730.2676 - learning_rate: 1.0000e-05\n",
      "Epoch 50/60\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 212ms/step - loss: 15736.8477 - mse: 15736.8477 - val_loss: 30001.6621 - val_mse: 30001.6621 - learning_rate: 1.0000e-05\n",
      "Epoch 51/60\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 209ms/step - loss: 15807.0645 - mse: 15807.0645 - val_loss: 29301.0703 - val_mse: 29301.0703 - learning_rate: 1.0000e-06\n",
      "Epoch 52/60\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 209ms/step - loss: 15886.8545 - mse: 15886.8545 - val_loss: 28590.2070 - val_mse: 28590.2070 - learning_rate: 1.0000e-06\n",
      "Epoch 53/60\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 211ms/step - loss: 15388.4141 - mse: 15388.4141 - val_loss: 27887.8711 - val_mse: 27887.8711 - learning_rate: 1.0000e-06\n",
      "Epoch 54/60\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 143ms/step - loss: 15653.5918 - mse: 15653.5918 - val_loss: 27181.9434 - val_mse: 27181.9434 - learning_rate: 1.0000e-06\n",
      "Epoch 55/60\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 214ms/step - loss: 15973.6094 - mse: 15973.6094 - val_loss: 26502.1289 - val_mse: 26502.1289 - learning_rate: 1.0000e-06\n",
      "Epoch 56/60\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 211ms/step - loss: 15742.9248 - mse: 15742.9248 - val_loss: 25847.1016 - val_mse: 25847.1016 - learning_rate: 1.0000e-06\n",
      "Epoch 57/60\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 148ms/step - loss: 15484.3896 - mse: 15484.3896 - val_loss: 25200.5508 - val_mse: 25200.5508 - learning_rate: 1.0000e-06\n",
      "Epoch 58/60\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 144ms/step - loss: 15850.8369 - mse: 15850.8369 - val_loss: 24561.5000 - val_mse: 24561.5000 - learning_rate: 1.0000e-06\n",
      "Epoch 59/60\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 148ms/step - loss: 15834.7480 - mse: 15834.7480 - val_loss: 23939.1074 - val_mse: 23939.1074 - learning_rate: 1.0000e-06\n",
      "Epoch 60/60\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 209ms/step - loss: 15377.8457 - mse: 15377.8457 - val_loss: 23330.4707 - val_mse: 23330.4707 - learning_rate: 1.0000e-06\n"
     ]
    }
   ],
   "source": [
    "model = build_mlp2(X_train.shape[1])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(),\n",
    "    loss=\"mse\",\n",
    "    metrics=[\"mse\"]\n",
    ")\n",
    "\n",
    "lr_callback = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=60,          # optimal\n",
    "    batch_size=4096,\n",
    "    callbacks=[lr_callback],\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d76cfb72-f7a7-4f8c-a214-774174f95276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 29953.6074 - mse: 29953.6074\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[29594.044921875, 29594.044921875]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4870b383-da85-43f7-ba0a-bb350df8ce93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Equilibrium Price MSE: 29593.708216773648\n"
     ]
    }
   ],
   "source": [
    "pred_bidask = model.predict(X_test)\n",
    "\n",
    "pred_mid = pred_bidask.mean(axis=1)\n",
    "true_mid = y_test.mean(axis=1)\n",
    "\n",
    "mse_mid = np.mean((pred_mid - true_mid) ** 2)\n",
    "print(\"Equilibrium Price MSE:\", mse_mid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c79bc8a-2e6f-4d3b-bbe1-b71f6645d220",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
